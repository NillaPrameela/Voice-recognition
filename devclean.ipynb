{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 not supported (please install/reinstall h5py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/pydub/utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import librosa\n",
    "import tflearn\n",
    "import wave\n",
    "import tensorflow as tf\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import speech_data\n",
    "from pydub import AudioSegment as audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files: 1797\n",
      "(10, ' speakers: ', ['Speaker1', 'Speaker0', 'Speaker3', 'Speaker2', 'Speaker5', 'Speaker4', 'Speaker7', 'Speaker6', 'Speaker9', 'Speaker8'])\n"
     ]
    }
   ],
   "source": [
    "# now put all of the mfccs into an array\n",
    "data = '/home/cc/working/data/devclean_seg/'\n",
    "os.chdir(data)\n",
    "speakers = speech_data.get_speakers(os.getcwd())\n",
    "audio_files = os.listdir(os.getcwd())\n",
    "mfccs = []\n",
    "Y = []\n",
    "for f in audio_files:\n",
    "  Y.append(speech_data.one_hot_from_item(speech_data.speaker(f), speakers))\n",
    "  y, sr = librosa.load(f)\n",
    "  mfccs.append(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = tflearn.input_data(shape=[None, 13, 44])\n",
    "net = tflearn.fully_connected(net, 64)\n",
    "net = tflearn.dropout(net, 0.6)\n",
    "net = tflearn.fully_connected(net, len(speakers), activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 29000  | total loss: \u001b[1m\u001b[32m0.77237\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1000 | loss: 0.77237 - acc: 0.9640 -- iter: 1797/1797\n",
      "Training Step: 29000  | total loss: \u001b[1m\u001b[32m0.77237\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1000 | loss: 0.77237 - acc: 0.9640 -- iter: 1797/1797\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model = tflearn.DNN(net)\n",
    "model.fit(mfccs, Y, n_epoch=1000, show_metric=True, snapshot_step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/cc/working/models/devclean/')\n",
    "model.save('devclean_train.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/cc/working/data/devclean_test/')\n",
    "\n",
    "test = []\n",
    "for f1 in os.listdir(os.getcwd()):\n",
    "  y, sr = librosa.load(f1)\n",
    "  test.append(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13))\n",
    "result=model.predict(test)\n",
    "c = 0\n",
    "for f,r in zip(os.listdir(os.getcwd()), result):\n",
    "  res = speech_data.one_hot_to_item(r, speakers)\n",
    "  if res in f:\n",
    "    c = c + 1\n",
    "acc = float(c) / float(len(test))\n",
    "print('Test set accuracy: %s' %str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
