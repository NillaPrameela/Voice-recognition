{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import wave\n",
    "from six.moves import urllib\n",
    "import tflearn\n",
    "import speech_data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/cc/Desktop')\n",
    "pcm_path = 'data/spoken_numbers_pcm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, ' speakers: ', ['Kathy', 'Alex', 'Bruce', 'Samantha', 'Vicki', 'Albert', 'Junior', 'Daniel', 'Princess', 'Fred', 'Tom', 'Ralph', 'Victoria', 'Steffi', 'Agnes'])\n",
      "('speakers', ['Kathy', 'Alex', 'Bruce', 'Samantha', 'Vicki', 'Albert', 'Junior', 'Daniel', 'Princess', 'Fred', 'Tom', 'Ralph', 'Victoria', 'Steffi', 'Agnes'])\n"
     ]
    }
   ],
   "source": [
    "speakers = data.get_speakers()\n",
    "number_classes=len(speakers)\n",
    "print('speakers',speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('speakers', ['Kathy', 'Alex', 'Bruce', 'Samantha', 'Vicki', 'Albert', 'Junior', 'Daniel', 'Princess', 'Fred', 'Tom', 'Ralph', 'Victoria', 'Steffi', 'Agnes'])\n"
     ]
    }
   ],
   "source": [
    "# get the number of classes...aka len(speakers)\n",
    "number_classes = len(speakers)\n",
    "print('speakers', speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, ' speakers: ', ['Kathy', 'Alex', 'Bruce', 'Samantha', 'Vicki', 'Albert', 'Junior', 'Daniel', 'Princess', 'Fred', 'Tom', 'Ralph', 'Victoria', 'Steffi', 'Agnes'])\n"
     ]
    }
   ],
   "source": [
    "WORD_WAVs=\"spoken_words\"\n",
    "batch=data.wave_batch_generator(batch_size=1000,source=WORD_WAVs,target=data.Target.speaker)\n",
    "X,Y=next(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classification\n",
    "tflearn.init_graph(num_cores=8, gpu_memory_fraction=0.5)\n",
    "\n",
    "net = tflearn.input_data(shape=[None, 8192]) #Two wave chunks\n",
    "net = tflearn.fully_connected(net, 64)\n",
    "net = tflearn.dropout(net, 0.5)\n",
    "net = tflearn.fully_connected(net, number_classes, activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1600  | total loss: \u001b[1m\u001b[32m0.20217\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 100 | loss: 0.20217 - acc: 0.9829 -- iter: 1000/1000\n",
      "Training Step: 1600  | total loss: \u001b[1m\u001b[32m0.20217\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 100 | loss: 0.20217 - acc: 0.9829 -- iter: 1000/1000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# this is the training step I think --> need to learn more about TFLearn\n",
    "model = tflearn.DNN(net)\n",
    "model.fit(X, Y, n_epoch=100, show_metric=True, snapshot_step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted speaker for 8_Bruce_260.wav : result = Daniel \n"
     ]
    }
   ],
   "source": [
    "demo_file = \"8_Bruce_260.wav\"\n",
    "demo=data.load_wav_file(demo_file)\n",
    "result=model.predict([demo])\n",
    "result=data.one_hot_to_item(result,speakers)\n",
    "print(\"predicted speaker for %s : result = %s \"%(demo_file,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
